# Semantic Search Demo

## Demo first (before any boring stuff), please!

A standalone deployment of this code be seen at [search.productiverage.com](https://search.productiverage.com).

And it's called by the JavaScript search logic on my static blog site, so if you searched [my blog](https://www.productiverage.com) for "[How can I write my own semantic search in .NET?](https://www.productiverage.com/Search?term=How+can+I+write+my+own+semantic+search+in+.NET%3F)", there will be some semantic search magic involved in the serving of the search results!*

\* *(In case you click the link and wonder why there's also an old blog post returned that talks about writing Roslyn Analysers, it's because the search does a lexical search as well, and that blog post just happens to include all of the words from the query)*

## So what am I looking at?

This web app will read in the embeddings generated by the `GenerateSimilarityEmbeddings` project (also in this repo) and allows you to search over the blog post data using the [bge-micro-v2](https://huggingface.co/TaylorAI/bge-micro-v2) semantic similarity model.

That embedding model effectively enables searching for the "most similar" results to a query - but the vector distances are only comparable in the context of that query. So, it might tell you that result A is a closer match than result B, because result A has a similarity score of 0.8 for the query, while result B has a score of 0.75, but that does *not* mean that a score of 0.8 will mean a good result for *every* query, or that 0.75 is never going to be a good result for any query.

The similarity scores are comparable for results against a *single query,* but the similarity scores from one query are *not* comparable to the similarity scores from another query.

This means that there is no "threshold" minimum similarity score that indicates "this is a good result". A semantic embedding vector search's result *might* retrieve the best matches for us, if there is good content for the query. Or they might merely be the "least bad" matches, where *all* of them are basically terrible.

To improve that situation, the vector search results are fed to the Cohere `rerank-v3.5` model via an API call, as that _can_ assign reliable scores, so that we remove poor quality results (and boost the genuinely good results to the top of the list, and the ensure that more mediocre ones go further down).

If you want to try running this code yourself, you'll need to:

1. Go to [cohere.com](https://cohere.com) and sign up to get an API key (it's free!) and configure a `COHERE_API_KEY` environment variable (or put it in an app settings file, as I'll show further down)
1. You'll need to run the `GenerateSimilarityEmbeddings` project, which will read the blog post content from this repo, break up longer content into chunks, calculate embeddings for those chunk, and write cache files to disk.

_Then_ you may run this project, which will copy the cache files that you just built so that it can implement the search.

**Note:** If you run this project without the cache files from `GenerateSimilarityEmbeddings` being available, you will see the message `Unknown Initialisation Error` in the web page when it starts up.

If you don't configure a Cohere API key, you will see the message `Reranker configuration missing` in the web page.

An alternative to setting an environment variable is to add an `appsettings.debug.json` file to the root of this project that contains the API key - it should look like this:

```
{
  "COHERE_API_KEY": "key-goes-here"
}
```

## Back to my example

Although I created this blog repo as an MVC application many years ago, I have a process that translates it into the static version that is hosted on GitHub Pages today ([www.productiverage.com](https://www.productiverage.com)).

The lexical search is performed client side - the indexed data that is necessary for the lexical search is bundled into the static GitHub Pages content (back in 2013, [I got all excited about the launch of neocities](https://www.productiverage.com/the-neocities-challenge-aka-the-full-text-indexer-goes-clientside) and tested the concept of a client-side search, and I use that now for my live site).

In March 2025, I extended the JavaScript to also call [search.productiverage.com](https://search.productiverage.com) so that the search results contain both semantic and lexical results.

One query that I see in Google Search Console, in the "what did people search for that resulted in them being linked to my site" list is -

> how to redirect to another controller action in mvc

The lexical search fails to find any matches, because the word "how" doesn't appear in the content. The *semantic* search, however, *does* return the result, and so now performing that query on my own blog works - yay, hybrid search! [Try it here](https://www.productiverage.com/Search?term=how+to+redirect+to+another+controller+action+in+mvc).

## Final question; what's this code style all about??

A few years ago, I worked at a company that leant into a functional programming style of writing C#, and I had recently been discussing using something like an `Either<L, R>` class in C# code with a current colleague for handling errors. It had got me thinking about how fun it was, and it inspired me to give it another go, hence the slightly unusual (for C#) style in this project. What are personal projects for, if not to experiment!